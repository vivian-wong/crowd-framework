{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935a0b4e",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6c421",
   "metadata": {},
   "source": [
    "This document is created to get you familiar with my horrible codes from this pedestrian crowd project. You can tell how horrible and unorganized I was based on the number of random notebooks I've prototyped throughout the last 1-2 year or so. But ignore those notebooks for now, as hopefully this notebook alone (with some debugging) should be able to get you the necessary components of a complete pipeline that will: \n",
    "1. Load the spatio-temporal crowd flow graphs\n",
    "    This graph dataset was created by integrating spatial and temporal information in the previous paper V. W. H. Wong and K. H. Law, Fusion of CCTV Video and Spatial Information for Automated Crowd Congestion Monitoring in Public Urban Spaces. Algorithms, Mar 2023, 16(3):154. https://doi.org/10.3390/a16030154. As opposed to this previous paper which relies only on one single-camera dataset to do the crowd flow estimation, there are two more self-collected data sources now integrated with multiple cameras. \n",
    "2. Prediction\n",
    "3. Visualization of hostpots \n",
    "\n",
    "Proposed title of a publication resulting from this line of work could be something along the lines of: \n",
    "\"ST-DIF: A spatio-temporal data integration framework to estimate pedestrian crowd flow from multi-camera surveillance in built environments\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19634f0",
   "metadata": {},
   "source": [
    "# 0. Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08765b",
   "metadata": {},
   "source": [
    "## 0.1. Open your terminal and create a new conda virtual environment from environment.yml. I always print out a conda cheatsheet (https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf)for this but now that there's chatgpt, it's probably useless. \n",
    "\n",
    "Ideally in the future we'd use Docker for our projects instead of conda virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b578608",
   "metadata": {},
   "source": [
    "## 0.2. Import packages\n",
    "Debug for version mismatch & unlisted packages in environment.yml if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37163e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2, glob, os, torch, math, torchvision, datetime\n",
    "from tqdm.notebook import tqdm \n",
    "import torch.nn.functional as F\n",
    "import configparser\n",
    "\n",
    "# my files\n",
    "from cmgraph import parse_gcs, image_to_world, GCSDatasetLoaderStatic, DatasetLoaderStatic\n",
    "from models import DenseGCNGRU, GRU_only, GCNGRU\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # should say 'cpu' if you're using mac.\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242919d7",
   "metadata": {},
   "source": [
    "# 1. Load data from Campus Crowd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e34dcf4",
   "metadata": {},
   "source": [
    "## 1.1. Load CSV tables\n",
    "The original pedestrian data I collected back at Stanford was videos. Due to IRB regulations they are anonymised and are stored in CSV. They are available to public use at https://github.com/vivian-wong/Campus-Crowd (though I really need to add a ReadMe soon...) Let's take a look at them with the help of pandas.\n",
    "\n",
    "We have 3 subsets of data: GCS (a public one), SEQ, Stadium (both collected at Stanford, post-processed with CNN after collecting videos). GCS will be loaded using the class GCSDatasetLoaderStatic. SEQ and Stadium will be loaded with  DatasetLoaderStatic. Both are dataset loaders I wrote; \n",
    "\n",
    "I moved some files into the data folder for better organization. If you get a file error you might need to debug a little bit here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LIST = ['GCS', 'SEQ', 'STADIUM_2023']\n",
    "DATASET = DATASET_LIST[0]\n",
    "\n",
    "if DATASET == 'GCS':\n",
    "    data_dir = \"data/GCS\"\n",
    "    trajs= parse_gcs(os.path.join(data_dir,\"Annotation\")) # 35 seconds to load\n",
    "    ZONE_LIST =[\n",
    "        (0, 0, 28, 14),\n",
    "        (28, 0, 55, 14),\n",
    "        (0, 14, 28, 24),\n",
    "        (28, 14, 55, 24),\n",
    "        (0, 24, 28, 35),\n",
    "        (28, 24, 55, 35),\n",
    "        (0, 35, 28, 45),\n",
    "        (28, 35, 55, 45),\n",
    "        (0, 45, 55, 55)\n",
    "    ]\n",
    "    loader = GCSDatasetLoaderStatic(\n",
    "        trajs=trajs,\n",
    "        ZONE_LIST = ZONE_LIST)\n",
    "if DATASET == 'SEQ': \n",
    "    data_dir = \"data/SEQ\"\n",
    "    configs_dict = get_configs_dict(os.path.join(data_dir,'SEQ.cfg'))\n",
    "    flow_df = pd.read_csv(os.path.join(data_dir,'flow_df_SEQ_1fps.csv'))\n",
    "    all_zone_dfs = [g for _,g in flow_df.groupby('egress_region')]\n",
    "    loader = DatasetLoaderStatic(all_zone_dfs,\n",
    "                                 configs_dict['CMGraph']['adjacency_mat'])\n",
    "if DATASET == 'STADIUM_2023': \n",
    "    data_dir = \"data/Stadium\"\n",
    "    configs_dict = get_configs_dict(os.path.join(data_dir,'Stadium_2023.cfg'))\n",
    "    flow_df = pd.read_csv(os.path.join(data_dir,'flow_df_stadium_2023_1fps.csv'))\n",
    "    all_zone_dfs = [g for _,g in flow_df.groupby('egress_region')]\n",
    "    loader = DatasetLoaderStatic(all_zone_dfs,\n",
    "                                 configs_dict['CMGraph']['adjacency_mat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b6298",
   "metadata": {},
   "source": [
    "## 1.2. Convert tables to node features of pytorch-geometric graphs. \n",
    "Node features are from the CSVs. Adjacency matrices of Stadium and SEQ are manually entered in the config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2154dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set any random forecasting horion\n",
    "forecasting_horizon=20\n",
    "\n",
    "# use the dataset loader I wrote to load pytorch dataset; I have a \"get_dataset\" method for both \n",
    "dataset = loader.get_dataset(num_timesteps_in=forecasting_horizon, \n",
    "                             num_timesteps_out=forecasting_horizon)\n",
    "print(\"Dataset type:  \", dataset) \n",
    "print(\"Number of samples / sequences: \",  len(list(dataset)))\n",
    "print(next(iter(dataset))) # Show first sample; You can read more about pytorch's dataset iterator on pytorch doc website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d644984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize traffic over time, only showing one region at a time right now.\n",
    "plt.figure(figsize=(20,5))\n",
    "region_number = 2 \n",
    "time = -1 # show from now to the the end of time.In python -1 means the last index. \n",
    "region_labels = [bucket.y[region_number][0].item() for bucket in list(dataset)[:time]]\n",
    "plt.plot(region_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213a44a",
   "metadata": {},
   "source": [
    "split dataset into train and test set. Usually what's common in the field is to have train, test, val. \n",
    "So maybe add val in the future but I worry that our dataset is too small, so let's just leave it for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "input_np = np.array(dataset.features) \n",
    "target_np = np.array(dataset.targets) \n",
    "input_tensor = torch.from_numpy(input_np).type(torch.FloatTensor).to(device)  # (B, N, F, T)\n",
    "target_tensor = torch.from_numpy(target_np).type(torch.FloatTensor).to(device)  # (B, N, T)\n",
    "dataset_new = torch.utils.data.TensorDataset(input_tensor, target_tensor)\n",
    "\n",
    "proportions = [0.7,0.3] # train: test ratio\n",
    "lengths = [int(p * len(dataset_new)) for p in proportions]\n",
    "lengths[-1] = len(dataset_new) - sum(lengths[:-1])\n",
    "train_dataset_new, test_dataset_new = torch.utils.data.random_split(dataset_new, lengths, generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_new, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_new, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Number of train buckets: \", len(list(train_dataset_new)))\n",
    "print(\"Number of test buckets: \", len(list(test_dataset_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb9858",
   "metadata": {},
   "source": [
    "# 2. Forecast \n",
    "To easily run multiple training experiments, I had the experiments in a bash file. See \"run_experiment.sh\", pasted below for reference:\n",
    "``` bash\n",
    "#!/bin/bash\n",
    "\n",
    "################ change forecasting horizon ################################ \n",
    "for FORECASTING_HORIZON in 20 60 120 240\n",
    "do\n",
    "    for MODEL in DenseGCNGRU GCNGRU GRU\n",
    "    do\n",
    "        for DATASET in GCS SEQ STADIUM_2023\n",
    "        do\n",
    "            # Call the experiment script with the specified parameters\n",
    "            python main.py \\\n",
    "                --DATASET $DATASET \\\n",
    "                --MODEL $MODEL \\\n",
    "                --forecasting_horizon $FORECASTING_HORIZON \\\n",
    "                --save_model True \\\n",
    "                --save_dir './checkpoints'\n",
    "        done\n",
    "    done\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5491592",
   "metadata": {},
   "source": [
    "An initial \"!\" in jupyter will run the line like a command line. Before you run the following line, you might need to first create a \"checkpoints\" folder if you don't have one already. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b937c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash script-name-here.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1124b1b9",
   "metadata": {},
   "source": [
    "# 3. Comparing results of ST-DIF's forecast with purely temporal (no spatial) information-based forecast\n",
    "Model checkpoint should be updated with MSE and MAE after running the sh script, because of line 279-283 in main.py:\n",
    "``` python\n",
    "# test model\n",
    "model, checkpoint_dict = testing_loop(model, test_loader, static_edge_index, checkpoint_dict=checkpoint_dict)\n",
    "# update save to include test mse and mae. \n",
    "if args.save_model:\n",
    "    save_or_update_checkpoint(checkpoint_dict, path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4533c",
   "metadata": {},
   "source": [
    "We can now tabulate these checkpoint results in a pandas dataframe for easy querying, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85670814",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dict_list = []\n",
    "for root, dirs, files in os.walk('./checkpoints'): \n",
    "    for name in files: \n",
    "        path = os.path.join(root, name)\n",
    "        checkpoint_dict = torch.load(path)\n",
    "        new_dict = checkpoint_dict.copy()\n",
    "        new_dict['model'] = name.split('_')[0]\n",
    "        new_dict['path'] = path\n",
    "        new_dict['forecasting_horizon'] = name.split('_')[-2]\n",
    "        new_dict['dataset'] = name.split('_')[-3]\n",
    "        if new_dict['dataset'] == '2023': \n",
    "            new_dict['dataset'] = 'STADIUM_2023'\n",
    "        del new_dict['model_state_dict']\n",
    "        del new_dict['optimizer_state_dict']\n",
    "        checkpoint_dict_list.append(new_dict)\n",
    "results_df = pd.DataFrame(checkpoint_dict_list)\n",
    "for k in ['forecasting_horizon', 'test_mae', 'test_mse']:\n",
    "    results_df[k] = pd.to_numeric(results_df[k])\n",
    "results_df.rename({})\n",
    "results_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac9a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'DenseGCNGRU': 'Dense-GCN-GRU',\n",
    "    'GCNGRU': 'GCN-GRU',\n",
    "    'STADIUM_2023': 'Stadium'\n",
    "}\n",
    "\n",
    "results_df = results_df.replace(replacements, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1db5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.query('forecasting_horizon==20')[['dataset','model','test_mse','test_mae']].sort_values(['dataset', 'model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a15695",
   "metadata": {},
   "source": [
    "# 4. potential TODOs, in the order of least difficult -> more difficult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2936bd1",
   "metadata": {},
   "source": [
    "## 4.1. Merge data from Grand Central Station, so that it's all one package that people can easily experiment with "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e44991",
   "metadata": {},
   "source": [
    "## 4.2. Convert to a simple package that's open source on github."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9a8bc",
   "metadata": {},
   "source": [
    "## 4.3. Add visualization tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6430fc82",
   "metadata": {},
   "source": [
    "## 4.4. Add stochasticity to graph for better crowd flow estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcbc8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
